<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Recent | Joris Paret</title>
    <link>https://jorisparet.github.io/post/</link>
      <atom:link href="https://jorisparet.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Recent</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language>
    <image>
      <url>https://jorisparet.github.io/media/icon_huf5b7e9305d8ca00c36bcf7194f7e4936_69678_512x512_fill_lanczos_center_3.png</url>
      <title>Recent</title>
      <link>https://jorisparet.github.io/post/</link>
    </image>
    
    <item>
      <title>Contribution to the 33rd Symposium on Fusion Technology</title>
      <link>https://jorisparet.github.io/post/2024-09-22_soft/</link>
      <pubDate>Sun, 22 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://jorisparet.github.io/post/2024-09-22_soft/</guid>
      <description>&lt;h1 id=&#34;soft-2024---preliminary-machine-learning-based-calibration-strategy-for-the-iter-tokamak-systems-monitor&#34;&gt;SOFT 2024 - Preliminary machine learning-based calibration strategy for the ITER Tokamak Systems Monitor&lt;/h1&gt;
&lt;p&gt;From &lt;strong&gt;September 22 to 27, 2024&lt;/strong&gt;, I had the opportunity to attend the &lt;strong&gt;33rd Symposium on Fusion Technology (SOFT 2024)&lt;/strong&gt; at &lt;strong&gt;Dublin City University, Ireland&lt;/strong&gt;. This premier event brought together researchers, engineers, and industry experts from around the world to discuss the latest advancements in fusion energy. The conference covered a wide range of topics, from reactor technology and materials science to plasma diagnostics and control systems, fostering valuable exchanges within the international fusion community.&lt;/p&gt;
&lt;p&gt;As part of my research at &lt;a href=&#34;https://www.iter.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ITER&lt;/a&gt;, I presented a scientific poster on a &lt;strong&gt;machine learning-based calibration strategy for the ITER Tokamak Systems Monitor (TSM)&lt;/strong&gt;, a software framework that aggregates data from multiple sensors installed across ITER to assess the machine&amp;rsquo;s health. This work focuses on improving the accuracy and reliability of numerical models that monitor the ITER tokamak&amp;rsquo;s structural dynamics. This work explores the use of sequential model-based optimization (SMBO) for the calibration of finite-element models. The goal is to refine structural models of the tokamak using a limited dataset, addressing the challenge of &lt;strong&gt;calibrating complex engineering systems under restrictive conditions&lt;/strong&gt;—a common limitation in fusion experiments due to the harsh operational environment and limited sensor accessibility.&lt;/p&gt;
&lt;p&gt;See the poster below or download it as a PDF &lt;a href=&#34;https://jorisparet.github.io/uploads/SOFT_2024_poster.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;poster&#34; srcset=&#34;
               /post/2024-09-22_soft/poster_hu2b9eaf6ec1672bcb03e93854b845f20e_4291946_71852c888db2027dc7c73db723bc93aa.webp 400w,
               /post/2024-09-22_soft/poster_hu2b9eaf6ec1672bcb03e93854b845f20e_4291946_c56e77fd0f3255097e4a45bac7ce2ad1.webp 760w,
               /post/2024-09-22_soft/poster_hu2b9eaf6ec1672bcb03e93854b845f20e_4291946_1200x1200_fit_q100_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://jorisparet.github.io/post/2024-09-22_soft/poster_hu2b9eaf6ec1672bcb03e93854b845f20e_4291946_71852c888db2027dc7c73db723bc93aa.webp&#34;
               width=&#34;538&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>“Dimensionality reduction of local structure in glassy binary mixtures” - The Journal of Chemical Physics</title>
      <link>https://jorisparet.github.io/post/2022-11-22_jcp/</link>
      <pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://jorisparet.github.io/post/2022-11-22_jcp/</guid>
      <description>&lt;h1 id=&#34;authors&#34;&gt;Authors&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Daniele Coslovich&lt;/li&gt;
&lt;li&gt;Robert L. Jack&lt;/li&gt;
&lt;li&gt;Joris Paret&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;We consider unsupervised learning methods for characterizing the disordered microscopic structure of supercooled liquids and glasses. Specifically, we perform dimensionality reduction of smooth structural descriptors that describe radial and bond-orientational correlations and assess the ability of the method to grasp the essential structural features of glassy binary mixtures. In several cases, a few collective variables account for the bulk of the structural fluctuations within the first coordination shell and also display a clear connection with the fluctuations of particle mobility. Fine-grained descriptors that characterize the radial dependence of bond-orientational order better capture the structural fluctuations relevant for particle mobility but are also more difficult to parameterize and to interpret. We also find that principal component analysis of bond-orientational order parameters provides identical results to neural network autoencoders while having the advantage of being easily interpretable. Overall, our results indicate that glassy binary mixtures have a broad spectrum of structural features. In the temperature range we investigate, some mixtures display well-defined locally favored structures, which are reflected in bimodal distributions of the structural variables identified by dimensionality reduction.&lt;/p&gt;
&lt;h1 id=&#34;article-and-data-availability&#34;&gt;Article and data availability&lt;/h1&gt;
&lt;p&gt;This paper is published &lt;a href=&#34;https://doi.org/10.1063/5.0128265&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Journal of Chemical Physics&lt;/a&gt; and is also available on &lt;a href=&#34;https://arxiv.org/abs/2211.01904&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv&lt;/a&gt;. The computation of descriptors and most of the dimensionality reduction analysis were performed using the &lt;a href=&#34;https://www.jorisparet.com/partycls&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;partycls&lt;/a&gt; package. Data analysis has been carried out using a reproducible workflow, deposited in the Zenodo &lt;a href=&#34;https://doi.org/10.5281/zenodo.7108317&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;public repository&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New major release of partycls (2.0.0)</title>
      <link>https://jorisparet.github.io/post/2022-10-24_partycls-2-0-0/</link>
      <pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://jorisparet.github.io/post/2022-10-24_partycls-2-0-0/</guid>
      <description>&lt;p&gt;A new major release of &lt;strong&gt;partycls&lt;/strong&gt; (v2.0.0) is now available on &lt;a href=&#34;https://github.com/jorisparet/partycls&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt; and &lt;a href=&#34;https://pypi.org/project/partycls/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyPI&lt;/a&gt;. The new &lt;a href=&#34;https://www.jorisparet.com/partycls&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;homepage&lt;/a&gt; also features new tutorials and a more consistent documentation, with a more detailed API presentation and cross-references between the different pages.&lt;/p&gt;
&lt;p&gt;The most important changes include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A variety of new structural descriptors and features (&lt;em&gt;e.g.&lt;/em&gt; Voronoi tessellation).&lt;/li&gt;
&lt;li&gt;A global optimization for most computations.&lt;/li&gt;
&lt;li&gt;Several bug fixes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See the &lt;a href=&#34;https://www.jorisparet.com/partycls/changelog.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;changelog&lt;/a&gt; for more details on this new version.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>First official release of hamoco</title>
      <link>https://jorisparet.github.io/post/2022-09-07_hamoco-first-release/</link>
      <pubDate>Wed, 07 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://jorisparet.github.io/post/2022-09-07_hamoco-first-release/</guid>
      <description>&lt;p&gt;&lt;strong&gt;hamoco&lt;/strong&gt; (&lt;em&gt;handy mouse controller&lt;/em&gt;) allows you to take control of your mouse by using hand gestures that are captured in real time by your webcam. It relies on &lt;a href=&#34;https://google.github.io/mediapipe/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MediaPipe&lt;/a&gt; to track hands, and the nature of the different hand poses are predicted by a small neural network built with &lt;a href=&#34;https://www.tensorflow.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TensorFlow&lt;/a&gt;. Basically, I thought that it might be fun to try and replicate the famous scene from the movie &lt;a href=&#34;https://en.wikipedia.org/wiki/Minority_Report_%28film%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Minority Report&lt;/a&gt; (spoiler: it&amp;rsquo;s cooler when Tom Cruise does it).&lt;/p&gt;
&lt;p&gt;You can perform all the basic mouse actions: &lt;em&gt;motion&lt;/em&gt;, &lt;em&gt;left/right click&lt;/em&gt;, &lt;em&gt;vertical scrolling&lt;/em&gt; and &lt;em&gt;drag &amp;amp; drop&lt;/em&gt;. There are many options to adjust the experience to your liking (&lt;em&gt;e.g.&lt;/em&gt; sensitivity, motion smoothing) and even an automated pipeline to record your own data and train a custom neural network tailored to your needs.&lt;/p&gt;
&lt;p&gt;The code is now available on &lt;a href=&#34;https://pypi.org/project/hamoco/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyPI&lt;/a&gt; in version 1.0.1, and you can also check out the page of the project on &lt;a href=&#34;https://github.com/jorisparet/hamoco&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Synth Road is now available on Android</title>
      <link>https://jorisparet.github.io/post/2022-06-11_synth-road-first-release/</link>
      <pubDate>Sat, 11 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://jorisparet.github.io/post/2022-06-11_synth-road-first-release/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Synth Road&lt;/strong&gt; is an arcade mobile game with synthwave vibes created using the &lt;a href=&#34;https://unity.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unity&lt;/a&gt; game engine. The goal is to go as far as possible on the road by avoiding the obstacles, and by using powers to help you do so. You can then publish your highscores on the leaderboard to compare your results with other players. The game is free to download on &lt;a href=&#34;https://play.google.com/store/apps/details?id=com.JorisParet.SynthRoad&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Play&lt;/a&gt;, and it contains a single &lt;strong&gt;optional&lt;/strong&gt; advertisement whose generated money (if any) will be given to humanitarian NGOs.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screenshot&#34; srcset=&#34;
               /post/2022-06-11_synth-road-first-release/screenshot_hu6d331ad27abbe38bd918b5eef0c16235_87861_db9f84950c1efad89660bc9d7b150d17.webp 400w,
               /post/2022-06-11_synth-road-first-release/screenshot_hu6d331ad27abbe38bd918b5eef0c16235_87861_4013f908aaeacf7461da3669d5a07f56.webp 760w,
               /post/2022-06-11_synth-road-first-release/screenshot_hu6d331ad27abbe38bd918b5eef0c16235_87861_1200x1200_fit_q100_h2_lanczos.webp 1200w&#34;
               src=&#34;https://jorisparet.github.io/post/2022-06-11_synth-road-first-release/screenshot_hu6d331ad27abbe38bd918b5eef0c16235_87861_db9f84950c1efad89660bc9d7b150d17.webp&#34;
               width=&#34;270&#34;
               height=&#34;540&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;This game is the logical consequence of two things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;My obsession for the indie game &lt;a href=&#34;https://www.mobiusdigitalgames.com/outer-wilds.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Outer Wilds&lt;/a&gt;, created by the geniuses at &lt;a href=&#34;https://www.mobiusdigitalgames.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mobius Digital Games&lt;/a&gt;, which was also created with Unity.&lt;/li&gt;
&lt;li&gt;The amazing YouTube channel of &lt;a href=&#34;https://www.youtube.com/c/SebastianLague&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sebastian Lague&lt;/a&gt;, where he creates various Unity projects and explains them in the most pedagogical, poetic and relaxing way.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These two things motivated me to experiment with Unity, and after a few weeks I wanted to prove to myself that I could create an entire project on my own from scratch. The most common mistake among amateur game developers is to directly start with unreasonably big projects, so I tried to keep it simple and came up with this mobile game. This was an opportunity to have a first look at various aspects of game design (gameplay, VFX, SFX, UI, etc.) and to learn more about the countless features of Unity. The game mechanics and visuals are simple, but for a first try I am pretty satisfied with the result, and I hope that I will have more time in the future for more elaborate projects.&lt;/p&gt;
&lt;p&gt;The code and all the game assets are available on the &lt;a href=&#34;https://github.com/jorisparet/synth-road&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub page&lt;/a&gt; of the project.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>“partycls: A Python package for structural clustering” - The Journal of Open Source Software</title>
      <link>https://jorisparet.github.io/post/2021-11-08_partycls-joss/</link>
      <pubDate>Mon, 08 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://jorisparet.github.io/post/2021-11-08_partycls-joss/</guid>
      <description>&lt;h1 id=&#34;presentation&#34;&gt;Presentation&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;partycls&lt;/strong&gt; is a Python framework for cluster analysis of systems of interacting particles. By grouping particles that share similar structural or dynamical properties, partycls enables rapid and unsupervised exploration of the system’s relevant features. It provides descriptors suitable for applications in condensed matter physics and integrates the necessary tools of unsupervised learning, such as dimensionality reduction, into a streamlined workflow. Through a simple and expressive interface, partycls allows one to open a trajectory file, perform a clustering based on the selected structural descriptor, and analyze and save the results with only a few lines of code.&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;related-publication&#34;&gt;Related publication&lt;/h1&gt;
&lt;p&gt;A &lt;a href=&#34;https://joss.theoj.org/papers/10.21105/joss.03723&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;short paper&lt;/a&gt; presenting the code, written in collaboration with &lt;a href=&#34;https://www2.units.it/daniele.coslovich/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Daniele Coslovich&lt;/a&gt;, was published in &lt;em&gt;The Journal of Open Source Software&lt;/em&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;short-example&#34;&gt;Short example&lt;/h1&gt;
&lt;p&gt;As a simple example, we consider the detection of the grain boundaries in a polycrystal formed by differently oriented FCC crystallites. This is easily achieved even with a simple radial descriptor, since the average radial distribution of particles at the boundaries is different than the one of the crystal in the bulk. The following short piece of code opens the input trajectory stored in the file &lt;code&gt;grains.xyz&lt;/code&gt;, computes the local radial distribution functions of the particles, applies a standard &lt;a href=&#34;https://en.wikipedia.org/wiki/Standard_score&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Z-Score&lt;/a&gt; normalization on the data, and finally performs a clustering using the &lt;a href=&#34;https://towardsdatascience.com/gaussian-mixture-models-explained-6986aaf5a95&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gaussian mixture model&lt;/a&gt; (GMM) with $K = 2$ clusters (default):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;partycls&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Workflow&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;wf&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Workflow&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;grains.xyz&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	      &lt;span class=&#34;n&#34;&gt;descriptor&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gr&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	      &lt;span class=&#34;n&#34;&gt;scaling&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;zscore&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	      &lt;span class=&#34;n&#34;&gt;clustering&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gmm&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;wf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Each of these steps is easily tunable, so as to change the workflow with little effort. The labels are available as a simple attribute of the &lt;code&gt;Workflow&lt;/code&gt; instance. Optionally, a set of output files can be produced for further analysis, including a trajectory file with the cluster labels. Quick visualization of the clusters, as in the following figure, is possible within partycls through optional visualization backends.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2021-11-08_partycls-joss/grains_huf7f5a4cdd2bca08a8f624fe01d8b681f_360916_485585a79fefc515a99cd33b3de36443.webp 400w,
               /post/2021-11-08_partycls-joss/grains_huf7f5a4cdd2bca08a8f624fe01d8b681f_360916_29b3139895507953058505ba0aa2846c.webp 760w,
               /post/2021-11-08_partycls-joss/grains_huf7f5a4cdd2bca08a8f624fe01d8b681f_360916_1200x1200_fit_q100_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://jorisparet.github.io/post/2021-11-08_partycls-joss/grains_huf7f5a4cdd2bca08a8f624fe01d8b681f_360916_485585a79fefc515a99cd33b3de36443.webp&#34;
               width=&#34;760&#34;
               height=&#34;217&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;(a)&lt;/strong&gt; A polycrystalline material with differently oriented FCC crystallites.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(b)&lt;/strong&gt; Using the individual radial distributions of the particles as structural descriptor, the algorithm identifies the crystalline domains (blue, $k = 0$) and the grain boundaries (red, $k = 1$).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(c)&lt;/strong&gt; The radial distribution functions restricted to these two clusters display a marked difference, with higher peaks for the crystals. The 3D visualization was performed with &lt;a href=&#34;https://www.ovito.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OVITO&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
